% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optimizer.R
\name{optim_ignite_sgd}
\alias{optim_ignite_sgd}
\title{SGD Optimizer as implemented in LibTorch}
\usage{
optim_ignite_sgd(
  params,
  lr,
  momentum = 0,
  dampening = 0,
  weight_decay = 0,
  nesterov = FALSE
)
}
\arguments{
\item{params}{(iterable): iterable of parameters to optimize or dicts defining
parameter groups}

\item{lr}{(float): learning rate}

\item{momentum}{(float, optional): momentum factor (default: 0)}

\item{dampening}{(float, optional): dampening for momentum (default: 0)}

\item{weight_decay}{(float, optional): weight decay (L2 penalty) (default: 0)}

\item{nesterov}{(bool, optional): enables Nesterov momentum (default: FALSE)}
}
\description{
SGD Optimizer as implemented in LibTorch
}
